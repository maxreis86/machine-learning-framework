{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy your final model\n",
    "* To succecfully run this notebook you need a python3.7 kernel with requirements in ./sagemaker-custom-image/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04859,
     "end_time": "2021-04-22T18:42:32.131294",
     "exception": false,
     "start_time": "2021-04-22T18:42:32.082704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This notebook will help you to do:\n",
    "* Pre-process raw data according to model requirements\n",
    "* Test prediction with the final model\n",
    "* Post-process the predict data and create the rating variable\n",
    "* Create the script handler.py for deploy using serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046916,
     "end_time": "2021-04-22T18:42:32.225806",
     "exception": false,
     "start_time": "2021-04-22T18:42:32.178890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 0.055908,
     "end_time": "2021-04-22T18:42:32.329142",
     "exception": false,
     "start_time": "2021-04-22T18:42:32.273234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Name\n",
    "ModelName = 'prop_apply_prospects'\n",
    "#Version\n",
    "ModelVersion = 'v12'\n",
    "#Model ID\n",
    "ModelId = ModelName+'_'+ModelVersion\n",
    "\n",
    "#Setting the model target variable name\n",
    "VarTarget = 'target'\n",
    "\n",
    "#process outputs such as MOJO model, images and performance of tested models\n",
    "PathModelMojo = './output_model/models/best/GBM_grid_1_AutoML_1_20220628_13109_model_7.zip/'\n",
    "\n",
    "#If you have a huge dataset, I should consider use a small sample for first execution\n",
    "PctSampleSize = 1\n",
    "\n",
    "#Bucket already created on S3\n",
    "bucket = 'data-science-lab'\n",
    "\n",
    "#Selected Feature difined in Data_Prep\n",
    "CAT = [ 'declared_seniority'\n",
    "       ,'last_company_classification'\n",
    "       ,'company_classification_migration'\n",
    "       ,'job_area'\n",
    "       ,'declared_seniority_migration'\n",
    "       ,'prospect_location_state'\n",
    "       ,'prospect_area_migration'\n",
    "      ]\n",
    "#float\n",
    "NUM = [ 'prospect_smart_skills_qty'\n",
    "       ,'prospect_experiences_qty'\n",
    "       ,'prospect_companies_qty'\n",
    "       ,'total_experience_months'\n",
    "       ,'experience_duration_months_min'\n",
    "       ,'experience_duration_months_clean_avg'\n",
    "       ,'experience_duration_months_clean_stddev'\n",
    "       ,'max_salary_offered'\n",
    "       ,'last_experience_duration_months_to_avg'\n",
    "       ,'prospect_linkedin_about_word_count'\n",
    "       ,'last_experience_descriptions_word_count'       \n",
    "       ,'import_policy_word_count'\n",
    "       ,'job_technical_requirements_word_count'\n",
    "       ,'job_validation_questions_word_count'\n",
    "       ,'all_company_classifications_count'\n",
    "      ]\n",
    "selected_features = CAT + NUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047515,
     "end_time": "2021-04-22T18:42:32.423393",
     "exception": false,
     "start_time": "2021-04-22T18:42:32.375878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/var/lang/lib/python37.zip')\n",
    "sys.path.append('/var/lang/lib/python3.7')\n",
    "sys.path.append('/var/lang/lib/python3.7/lib-dynload')\n",
    "sys.path.append('/var/lang/lib/python3.7/site-packages')\n",
    "sys.path.remove('/opt/.sagemakerinternal/conda/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 9.765238,
     "end_time": "2021-04-22T18:42:42.235677",
     "exception": false,
     "start_time": "2021-04-22T18:42:32.470439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import boto3\n",
    "import queue\n",
    "from threading import Thread\n",
    "from boto3.dynamodb.conditions import Key\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Read raw data from application source and transform before predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is necessary to create two boto3 to work with multiple threads. One for each thread\n",
    "\n",
    "#boto3_Session para a tabela jobs\n",
    "boto_jobs = boto3.Session(region_name='us-east-1',\n",
    "    aws_access_key_id='xxxx',\n",
    "    aws_secret_access_key='xxxxx',\n",
    "    aws_session_token='xxxxxx')\n",
    "\n",
    "#boto3_Session para a tabela prospects\n",
    "boto_prospects = boto3.Session(region_name='us-east-1',\n",
    "    aws_access_key_id='xxxx',\n",
    "    aws_secret_access_key='xxxxx',\n",
    "    aws_session_token='xxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample raw data from application\n",
    "event={\n",
    "    \"queryStringParameters\":{\"jobId\":\"2300\",\n",
    "                             \"linkedinUsername\":\"fernando-heitor\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedinUsername = event['queryStringParameters']['linkedinUsername']\n",
    "jobId = event['queryStringParameters']['jobId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar funcoes de consulta ao DynamoDB para serem executadas em paralelo diminuindo o tempo\n",
    "def dynamodb_jobs_clients_companies(jobId, boto3):\n",
    "    jobsTable = boto3.resource('dynamodb').Table('prod-jobsTable').query(\n",
    "        IndexName='GSI1',\n",
    "        KeyConditionExpression=Key('backofficeId').eq(int(jobId))\n",
    "    )['Items']\n",
    "\n",
    "    clientsTable = boto3.resource('dynamodb').Table('prod-clientsTable').query(\n",
    "        IndexName='idBackofficeIndex',\n",
    "        KeyConditionExpression = (Key('source').eq('backoffice') & Key('idBackoffice').eq(int(jobsTable[0]['companyId'])))\n",
    "    )['Items']\n",
    "    \n",
    "    if clientsTable[0]['linkedinURL'][-1] == '/':\n",
    "        linkedin_company_user_name = clientsTable[0]['linkedinURL'].split('/')[-2]\n",
    "    else:\n",
    "        linkedin_company_user_name = clientsTable[0]['linkedinURL'].split('/')[-1]\n",
    "\n",
    "    linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "        IndexName='LinkedinUsernameIndex',\n",
    "        KeyConditionExpression=Key('linkedinUsername').eq(linkedin_company_user_name)\n",
    "    )['Items']\n",
    "    \n",
    "    return_object = {} \n",
    "    return_object['jobsTable'] = jobsTable\n",
    "    return_object['linkedinCompanies'] = linkedinCompanies\n",
    "    return return_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_classification_const(s):\n",
    "    if s == 'Empresa pequena':\n",
    "        out='Empresa pequena'\n",
    "    elif s == 'Empresas pequenas':\n",
    "        out='Empresa pequena'\n",
    "    elif s == 'Empresa Tradicional A':\n",
    "        out='Empresa Tradicional A'\n",
    "    elif s == 'Empresa Tradicional B':\n",
    "        out='Empresa Tradicional B'\n",
    "    elif s == 'Empresa Tradicional C':\n",
    "        out='Empresa Tradicional C'\n",
    "    elif s == 'High Tech A':\n",
    "        out='High Tech A'\n",
    "    elif s == 'High Tech B':\n",
    "        out='High Tech B'\n",
    "    elif s == 'High Tech C':\n",
    "        out='High Tech C'\n",
    "    elif s == 'High Tech D':\n",
    "        out='High Tech D'\n",
    "    elif s == 'Software House A':\n",
    "        out='Software House A'\n",
    "    elif s == 'Software House B':\n",
    "        out='Software House B'\n",
    "    elif s == 'Software House C':\n",
    "        out='Software House C'\n",
    "    elif s == 'not_mapped':\n",
    "        out='Missing'\n",
    "    elif s in ('', 'null', None, 'None'):\n",
    "        out='Missing'\n",
    "    else:\n",
    "        out='UNKNOWN'\n",
    "    return out\n",
    "\n",
    "def dynamodb_prospects_companies(linkedinUsername, boto3):\n",
    "    prospectsTable = boto3.resource('dynamodb').Table('prod-prospectsTable').get_item(Key={'linkedinUsername': linkedinUsername})['Item']\n",
    "\n",
    "    dict_prospects={}\n",
    "    total_experience_months=[]\n",
    "    total_experience_months_clean=[]\n",
    "    prospect_companies=[]\n",
    "    all_company_classifications=[]\n",
    "    \n",
    "    for i in range(len(prospectsTable['experiences'])):\n",
    "        try:        \n",
    "            prospect_companies.append(prospectsTable['experiences'][i]['linkedinCompanyName'])\n",
    "\n",
    "            try:\n",
    "                linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "                    IndexName='LinkedinUsernameIndex',\n",
    "                    KeyConditionExpression=Key('linkedinUsername').eq(prospectsTable['experiences'][i]['linkedinCompanyUsername'])\n",
    "                )['Items']\n",
    "                all_company_classifications.append(company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' ')))\n",
    "            except:\n",
    "                try:\n",
    "                    linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "                        IndexName='LinkedinIdIndex',\n",
    "                        KeyConditionExpression=Key('linkedinId').eq(int(prospectsTable['experiences'][i]['linkedinCompanyId']))\n",
    "                    )['Items']\n",
    "                    all_company_classifications.append(company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' ')))\n",
    "                except:\n",
    "                    all_company_classifications.append('Missing')\n",
    "\n",
    "            if i == 0:\n",
    "                if prospectsTable['experiences'][i]['to'] == None:\n",
    "                    total_experience_months.append((int((dt.now() - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                else:\n",
    "                    total_experience_months.append((int((dt.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                #precisa colocar o copy porque a variavel total_experience sera alterada, mas a last_experience nao pode mais ser alterada\n",
    "                last_experience_duration_months = total_experience_months.copy()\n",
    "                try:\n",
    "                    last_experience_descriptions = prospectsTable['experiences'][i]['description']\n",
    "                except:\n",
    "                    last_experience_descriptions = ''            \n",
    "            else:\n",
    "                if prospectsTable['experiences'][i]['to'] == None:\n",
    "                    total_experience_months.append((int((dt.now() - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                    total_experience_months_clean.append((int((dt.now() - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                else:\n",
    "                    total_experience_months.append((int((dt.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                    total_experience_months_clean.append((int((dt.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "        except:\n",
    "            last_experience_duration_months=[0]\n",
    "            total_experience_months=[0]\n",
    "            last_experience_descriptions = ''\n",
    "            all_company_classifications = ['Missing']\n",
    "\n",
    "    dict_prospects['prospect_companies_qty'] = len(set(prospect_companies))\n",
    "    dict_prospects['total_experience_months'] = sum(total_experience_months)\n",
    "    dict_prospects['experience_duration_months_min'] = min(total_experience_months)\n",
    "    dict_prospects['experience_duration_months_clean_avg'] = np.mean((total_experience_months_clean))\n",
    "    dict_prospects['experience_duration_months_clean_stddev'] =  np.std(total_experience_months_clean, ddof = 1)\n",
    "    dict_prospects['last_experience_duration_months_to_avg'] = float(last_experience_duration_months[0]) - float(dict_prospects['experience_duration_months_clean_avg'])\n",
    "    dict_prospects['last_experience_descriptions_word_count'] = float(len(last_experience_descriptions.split()))\n",
    "    dict_prospects['last_company_classification'] = all_company_classifications[0]\n",
    "    dict_prospects['all_company_classifications_word_count'] = float(len('; '.join(map(str, all_company_classifications)).replace(\"||\", \",\").split()))\n",
    "    \n",
    "    return_object = {} \n",
    "    return_object['prospectsTable'] = prospectsTable\n",
    "    return_object['dict_prospects'] = dict_prospects\n",
    "    return return_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamodb_jobs_clients_companies(jobId, boto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar q1 e q2 para receber o return de cada funcao\n",
    "q1 = queue.Queue()\n",
    "q2 = queue.Queue()\n",
    "#criar as duas tarefas\n",
    "t1 = Thread(target = lambda q, arg1, arg2 : q.put(dynamodb_jobs_clients_companies(arg1, arg2)), args = (q1, jobId, boto_jobs))\n",
    "t2 = Thread(target = lambda q, arg1, arg2 : q.put(dynamodb_prospects_companies(arg1, arg2)), args = (q2, linkedinUsername, boto_prospects))\n",
    "#iniciar as duas tarefas simutaneamente.\n",
    "t1.start()\n",
    "t2.start()\n",
    "#unir as duas tarefas para garantir que a proxima tarefa seja iniciada somente quando as duas terminarem\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "#recebar o return da funcao\n",
    "while not q1.empty():\n",
    "    return_object_jobs_clients_companies = q1.get()\n",
    "while not q2.empty():\n",
    "    return_object_prospects_companies = q2.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobsTable = return_object_jobs_clients_companies['jobsTable']\n",
    "linkedinCompanies = return_object_jobs_clients_companies['linkedinCompanies']\n",
    "prospectsTable = return_object_prospects_companies['prospectsTable']\n",
    "dict_prospects = return_object_prospects_companies['dict_prospects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_prospects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prod-jobsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declared_seniority_migration\n",
    "# prospect_area_migration\n",
    "# max_salary_offered\n",
    "# import_policy_word_count\n",
    "# job_technical_requirements_word_count\n",
    "# job_validation_questions_word_count\n",
    "# company_classification_migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original columns names in JobsTable in DynamoDB\n",
    "declared_seniority_migration = job_seniority = 'profile.seniority'\n",
    "prospect_area_migration = job_area = 'area'\n",
    "max_salary_offered = 'maxsalary'\n",
    "import_policy_word_count = 'importPolicy'\n",
    "job_technical_requirements_word_count = 'alignments.intendedTechnicalInfo'\n",
    "job_validation_questions_word_count = 'validationquestions'\n",
    "company_classification_migration = company_classification = \"last_company_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobsTable = boto3.resource('dynamodb').Table('prod-jobsTable').query(\n",
    "#     IndexName='GSI1',\n",
    "#     KeyConditionExpression=Key('backofficeId').eq(int(event['queryStringParameters']['jobId']))\n",
    "# )['Items']\n",
    "# jobsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start empty dictionary\n",
    "dict_jobs={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_seniority': 'Specialist'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## job_seniority = 'profile.seniority'\n",
    "def job_seniority_const(s):\n",
    "    if s in (\"Júnior\", \"junior\", \"Junior\"):\n",
    "        out=\"Junior\"\n",
    "    elif s in (\"Pleno\", \"pleno\"):\n",
    "        out=\"Mid-level\"\n",
    "    elif s in (\"Senior\", \"Sênior\", \"senior\"):\n",
    "        out=\"Senior\"\n",
    "    elif s in (\"Especialista\", \"especialista\"):\n",
    "        out=\"Specialist\"\n",
    "    elif s == \"Tech Lead\":\n",
    "        out=\"Tech Lead\"\n",
    "    elif s == \"Tech Manager\":\n",
    "        out=\"Tech Manager\"\n",
    "    elif s in ('', 'null', None, 'None'):\n",
    "        out=\"Missing\"\n",
    "    else:\n",
    "        out=\"UNKNOWN\"\n",
    "    return out\n",
    "\n",
    "dict_jobs['job_seniority'] = job_seniority_const(jobsTable[0]['profile']['seniority'])\n",
    "dict_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_seniority': 'Specialist', 'job_area': 'Agile'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## job_area = 'area'\n",
    "try:\n",
    "    dict_jobs['job_area'] = jobsTable[0]['area']\n",
    "except:\n",
    "    dict_jobs['job_area'] = 'Missing'\n",
    "dict_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_seniority': 'Specialist',\n",
       " 'job_area': 'Agile',\n",
       " 'max_salary_offered': 14000.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## max_salary_offered = 'maxsalary'\n",
    "try:\n",
    "    dict_jobs['max_salary_offered'] = float(jobsTable[0]['maxSalary'])\n",
    "except:\n",
    "    dict_jobs['max_salary_offered'] = 0\n",
    "dict_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_seniority': 'Specialist',\n",
       " 'job_area': 'Agile',\n",
       " 'max_salary_offered': 14000.0,\n",
       " 'import_policy_word_count': 21.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import_policy_word_count = 'importPolicy'\n",
    "try:\n",
    "    dict_jobs['import_policy_word_count'] = float(len(jobsTable[0]['importPolicy'].split()))\n",
    "except:\n",
    "    dict_jobs['import_policy_word_count'] = 0\n",
    "dict_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_seniority': 'Specialist',\n",
       " 'job_area': 'Agile',\n",
       " 'max_salary_offered': 14000.0,\n",
       " 'import_policy_word_count': 21.0,\n",
       " 'job_technical_requirements_word_count': 135.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## job_technical_requirements_word_count = 'alignments.intendedTechnicalInfo'\n",
    "try:\n",
    "    dict_jobs['job_technical_requirements_word_count'] = float(len(jobsTable[0]['alignments']['intendedTechnicalInfo'].split()))\n",
    "except:\n",
    "    dict_jobs['job_technical_requirements_word_count'] = 0\n",
    "dict_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_seniority': 'Specialist',\n",
       " 'job_area': 'Agile',\n",
       " 'max_salary_offered': 14000.0,\n",
       " 'import_policy_word_count': 21.0,\n",
       " 'job_technical_requirements_word_count': 135.0,\n",
       " 'job_validation_questions_word_count': 126.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## job_validation_questions_word_count = 'validationQuestions'\n",
    "try:\n",
    "    dict_jobs['job_validation_questions_word_count'] = float(len(jobsTable[0]['validationQuestions'].split()))\n",
    "except:\n",
    "    dict_jobs['job_validation_questions_word_count'] = 0\n",
    "dict_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_seniority': 'Specialist',\n",
       " 'job_area': 'Agile',\n",
       " 'max_salary_offered': 14000.0,\n",
       " 'import_policy_word_count': 21.0,\n",
       " 'job_technical_requirements_word_count': 135.0,\n",
       " 'job_validation_questions_word_count': 126.0,\n",
       " 'job_company_classification': 'Empresa Tradicional B'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#company_classification\n",
    "try:\n",
    "#     clientsTable = boto3.resource('dynamodb').Table('prod-clientsTable').query(\n",
    "#         IndexName='idBackofficeIndex',\n",
    "#         KeyConditionExpression = (Key('source').eq('backoffice') & Key('idBackoffice').eq(int(jobsTable[0]['companyId'])))\n",
    "#     )['Items']\n",
    "\n",
    "#     if clientsTable[0]['linkedinURL'][-1] == '/':\n",
    "#         linkedin_company_user_name = clientsTable[0]['linkedinURL'].split('/')[-2]\n",
    "#     else:\n",
    "#         linkedin_company_user_name = clientsTable[0]['linkedinURL'].split('/')[-1]\n",
    "    \n",
    "#     linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "#         IndexName='LinkedinUsernameIndex',\n",
    "#         KeyConditionExpression=Key('linkedinUsername').eq(linkedin_company_user_name)\n",
    "#     )['Items']\n",
    "\n",
    "    dict_jobs['job_company_classification'] = company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' '))\n",
    "except:\n",
    "    dict_jobs['job_company_classification'] = 'Missing'\n",
    "    \n",
    "dict_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prod-prospectsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'declared_seniority' ok\n",
    "# 'last_company_classification' ok\n",
    "# 'company_classification_migration' ok\n",
    "# 'declared_seniority_migration' ok\n",
    "# 'prospect_location_state' ok\n",
    "# 'prospect_area_migration' ok\n",
    "# 'prospect_smart_skills_qty' ok\n",
    "# 'prospect_experiences_qty' ok\n",
    "# 'prospect_companies_qty' ok\n",
    "# 'total_experience_months' ok \n",
    "# 'experience_duration_months_min' ok\n",
    "# 'experience_duration_months_clean_avg' ok\n",
    "# 'experience_duration_months_clean_stddev' ok\n",
    "# 'last_experience_duration_months_to_avg' ok\n",
    "# 'prospect_linkedin_about_word_count' ok\n",
    "# 'last_experience_descriptions_word_count' ok\n",
    "# 'all_company_classifications_word_count' \n",
    "#Colocar try exepction em todas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original columns names in ProspectsTable in DynamoDB\n",
    "declared_seniority = 'declaredseniority'\n",
    "\n",
    "prospect_smart_skills_qty =\"\"\"\n",
    "#Treat the stack column\n",
    "prospects_smart_skills1 = sdf_prospects_dedup4.select(\"linkedin_user_name\", F.explode(\"smarttags\"))\n",
    "\n",
    "#Rename columns\n",
    "prospects_smart_skills2 = prospects_smart_skills1.withColumn('prospect_smart_skill', F.col('col.tag'))\\\n",
    ".withColumn('smart_skill_count', F.col('col.count')).drop('col')\n",
    "\n",
    "#handle nomenclature of skills\n",
    "prospects_smart_skills3 = prospects_smart_skills2.withColumn('prospect_smart_skill', F.translate(F.lower(F.col('prospect_smart_skill')), \" \", \"-\"))\\\n",
    ".withColumn('prospect_smart_skill', F.translate(F.col('prospect_smart_skill'), \"/\", \"-\"))\\\n",
    ".withColumn('prospect_smart_skill', F.translate(F.col('prospect_smart_skill'), \".\", \"\"))\n",
    "\n",
    "select \"linkedin_user_name\", count(\"prospect_smart_skill\") as prospect_smart_skills_qty, sum(\"smart_skill_count\") as prospect_smart_skills_sum, avg(\"smart_skill_count\") as prospect_smart_skills_avg ,array_agg(prospect_smart_skill) as all_prospect_smart_skills from \"prod-lakehouse-mirror\".\"prospects_smart_skills\" group by \"linkedin_user_name\"\n",
    "\"\"\"\n",
    "\n",
    "prospect_experiences_qty =\"\"\"\n",
    "#Treat the stack column\n",
    "prospects_experiences1 = sdf_prospects_dedup4.select(\"linkedin_user_name\", F.explode(\"experiences\"))\n",
    "#Flatten nested columns\n",
    "prospects_experiences2 = flatten_df(prospects_experiences1)\n",
    "#Rename columns\n",
    "prospects_experiences3 = prospects_experiences2.withColumnRenamed('col_linkedinCompanyName', 'linkedin_company_name')\\\n",
    ".withColumn('experience_position', F.coalesce(F.col('col_role'), F.col('col_position')).cast(StringType()))\\\n",
    ".withColumn('company_linkedin_id', F.coalesce(F.col('col_id'), F.col('col_linkedincompanyid')).cast(LongType()))\\\n",
    ".withColumnRenamed('col_linkedinCompanyUsername', 'linkedin_company_user_name')\\\n",
    ".withColumnRenamed('col_description', 'experience_description')\\\n",
    ".withColumn('experience_date_from', F.substring('col_from', 1, 10))\\\n",
    ".withColumn('experience_date_to', F.substring('col_to', 1, 10))\\\n",
    ".withColumn('experience_date_to_tmp', F.when(F.col('experience_date_to').isNull(), dt.datetime.now()).otherwise(F.col('experience_date_to')))\\\n",
    ".withColumn('experience_duration_months', ((F.datediff(F.col('experience_date_to_tmp'), F.col('experience_date_from')))/30).cast(LongType())).drop('col_to','col_from', 'experience_date_to_tmp', 'col_role', 'col_position', 'col_id', 'col_linkedincompanyid')\n",
    "\n",
    ",count(c2.linkedin_company_name) as prospect_experiences_qty\n",
    "from \"prod-lakehouse-mirror\".\"prospects_experiences\"\n",
    "\"\"\"\n",
    "prospect_companies_qty = ',count(distinct c2.linkedin_company_name) as prospect_companies_qty'\n",
    "\n",
    "total_experience_months = \"\"\"\n",
    "#Treat the stack column\n",
    "prospects_experiences1 = sdf_prospects_dedup4.select(\"linkedin_user_name\", F.explode(\"experiences\"))\n",
    "#Flatten nested columns\n",
    "prospects_experiences2 = flatten_df(prospects_experiences1)\n",
    "#Rename columns\n",
    "prospects_experiences3 = prospects_experiences2.withColumnRenamed('col_linkedinCompanyName', 'linkedin_company_name')\\\n",
    ".withColumn('experience_position', F.coalesce(F.col('col_role'), F.col('col_position')).cast(StringType()))\\\n",
    ".withColumn('company_linkedin_id', F.coalesce(F.col('col_id'), F.col('col_linkedincompanyid')).cast(LongType()))\\\n",
    ".withColumnRenamed('col_linkedinCompanyUsername', 'linkedin_company_user_name')\\\n",
    ".withColumnRenamed('col_description', 'experience_description')\\\n",
    ".withColumn('experience_date_from', F.substring('col_from', 1, 10))\\\n",
    ".withColumn('experience_date_to', F.substring('col_to', 1, 10))\\\n",
    ".withColumn('experience_date_to_tmp', F.when(F.col('experience_date_to').isNull(), dt.datetime.now()).otherwise(F.col('experience_date_to')))\\\n",
    ".withColumn('experience_duration_months', ((F.datediff(F.col('experience_date_to_tmp'), F.col('experience_date_from')))/30).cast(LongType()))\n",
    "\n",
    ",sum(c2.experience_duration_months) as total_experience_months'\n",
    "\"\"\"\n",
    "\n",
    "experience_duration_months_min = \"min(c2.experience_duration_months) as experience_duration_months_min\"\n",
    "\n",
    "experience_duration_months_clean_avg = \"\"\"\n",
    ",b2.experience_duration_months as experience_duration_months_tmp1\n",
    "\n",
    ",case when experience_rank = 1 then null else c3.experience_duration_months_tmp1 end as experience_duration_months_clean\n",
    "\n",
    ",avg(c2.experience_duration_months_clean) as experience_duration_months_clean_avg\n",
    "\"\"\"\n",
    "experience_duration_months_clean_stddev = 'stddev(c2.experience_duration_months_clean) as experience_duration_months_clean_stddev'\n",
    "\n",
    "last_company_classification = \"\"\"\n",
    "def company_classification_const(s):\n",
    "    if s == 'Empresa pequena':\n",
    "        out='Empresa pequena'\n",
    "    elif s == 'Empresas pequenas':\n",
    "        out='Empresa pequena'\n",
    "    elif s == 'Empresa Tradicional A':\n",
    "        out='Empresa Tradicional A'\n",
    "    elif s == 'Empresa Tradicional B':\n",
    "        out='Empresa Tradicional B'\n",
    "    elif s == 'Empresa Tradicional C':\n",
    "        out='Empresa Tradicional C'\n",
    "    elif s == 'High Tech A':\n",
    "        out='High Tech A'\n",
    "    elif s == 'High Tech B':\n",
    "        out='High Tech B'\n",
    "    elif s == 'High Tech C':\n",
    "        out='High Tech C'\n",
    "    elif s == 'High Tech D':\n",
    "        out='High Tech D'\n",
    "    elif s == 'Software House A':\n",
    "        out='Software House A'\n",
    "    elif s == 'Software House B':\n",
    "        out='Software House B'\n",
    "    elif s == 'Software House C':\n",
    "        out='Software House C'\n",
    "    elif s == 'not_mapped':\n",
    "        out='Missing'\n",
    "    elif s in ('', 'null', None, 'None'):\n",
    "        out='Missing'\n",
    "    else:\n",
    "        out='UNKNOWN'\n",
    "    return out\n",
    "company_classification_func = F.udf(company_classification_const, StringType())\n",
    "\n",
    "sdf_linkedincompanies_dedup2 = sdf_linkedincompanies_dedup1.drop('partition_0', 'partition_1', 'partition_2', 'partition_3')\\\n",
    ".withColumn(\"createdat\", (F.to_timestamp(\"createdat\") - F.expr('INTERVAL 3 HOURS')))\\\n",
    ".withColumn(\"updatedat\", (F.to_timestamp(\"updatedat\") - F.expr('INTERVAL 3 HOURS')))\\\n",
    ".withColumnRenamed('searchcount', 'qty_search')\\\n",
    ".withColumnRenamed('linkedinusername', 'linkedin_company_user_name')\\\n",
    ".withColumnRenamed('linkedinid', 'company_linkedin_id')\\\n",
    ".withColumnRenamed('city', 'company_city')\\\n",
    ".withColumnRenamed('companysize', 'company_size')\\\n",
    ".withColumnRenamed('name', 'company_name')\\\n",
    ".withColumnRenamed('founded', 'company_foundation_year')\\\n",
    ".withColumnRenamed('employeecount', 'qty_company_employees')\\\n",
    ".withColumnRenamed('categorydescription', 'classification_description')\\\n",
    ".withColumnRenamed('state', 'company_state')\\\n",
    ".withColumn('category', F.regexp_replace('category', ' - ', ' '))\\\n",
    ".withColumn(\"company_classification\", company_classification_func(F.trim(F.col('category'))))\\\n",
    "\n",
    "datasource_companies_id = glueContext.create_dynamic_frame.from_catalog(database = \"prod-lakehouse-mirror\", table_name = \"companies\", transformation_ctx = \"datasource_companies\", additional_options={\"mergeSchema\": \"true\"}).toDF()\\\n",
    ".select('linkedin_company_user_name', 'company_linkedin_id', 'company_classification').where(F.col('company_classification') != 'Missing')\\\n",
    ".withColumn('linkedin_company_user_name_tmp', F.col('linkedin_company_user_name')).dropDuplicates(subset = [\"company_linkedin_id\"])\n",
    "\n",
    "prospects_experiences6 = prospects_experiences5.alias('df1').join(datasource_companies_username.alias('df2'),\n",
    "                              on = prospects_experiences5['linkedin_company_user_name'] == datasource_companies_username['linkedin_company_user_name'],\n",
    "                              how = 'left')\\\n",
    "                         .select('df1.*',\n",
    "                                 'df2.company_classification').withColumnRenamed('company_classification', 'company_classification_user').alias('df3').join(datasource_companies_id.alias('df4'),\n",
    "                              on = prospects_experiences5['company_linkedin_id'] == datasource_companies_id['company_linkedin_id'],\n",
    "                              how = 'left')\\\n",
    "                         .select('df3.*',\n",
    "                                 'df4.company_classification',\n",
    "                                 'df4.linkedin_company_user_name_tmp').withColumnRenamed('company_classification', 'company_classification_id')\n",
    "\n",
    "prospects_experiences7 = prospects_experiences6.withColumn('company_classification', F.coalesce(F.col('company_classification_user'), F.col('company_classification_id')).cast(StringType()))\\\n",
    ".withColumn('company_classification', F.coalesce(F.col('company_classification'), F.lit('Missing')).cast(StringType()))\\\n",
    ".withColumn('linkedin_company_user_name', F.coalesce(F.col('linkedin_company_user_name'), F.col('linkedin_company_user_name_tmp')).cast(StringType()))\n",
    "\n",
    "first_value(b2.company_classification) over(partition by a2.linkedin_user_name, a2.approach_id order by b2.experience_date_from desc) as last_company_classification'\n",
    "\"\"\"\n",
    "\n",
    "company_classification_migration = last_company_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prospectsTable = boto3.resource('dynamodb').Table('prod-prospectsTable').get_item(Key={'linkedinUsername': event['queryStringParameters']['linkedinUsername']})['Item']\n",
    "# prospectsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start empty dictionary\n",
    "# dict_prospects={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## declared_seniority = 'declaredseniority'\n",
    "try:\n",
    "    dict_prospects['declared_seniority'] = job_seniority_const(prospectsTable['declaredSeniority'])\n",
    "except:\n",
    "    dict_prospects['declared_seniority'] = 'Missing'\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'declared_seniority_migration'\n",
    "dict_prospects['declared_seniority_migration'] = (dict_prospects['declared_seniority']+'-to-'+dict_jobs['job_seniority']).strip()\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist',\n",
       " 'prospect_location_state': 'São Paulo'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prospect_location_state\n",
    "\n",
    "#Criacao das variaveis de pais com base na variavel propesct_location do linkedin. Para comparar abordagens de talentos que moram fora do Brasil\n",
    "def prospect_country(country):\n",
    "    if pd.isna(country):\n",
    "        return \"Missing\"\n",
    "    elif country == 'São Paulo':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Rio de Janeiro':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Campinas':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Belo Horizonte':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Porto Alegre':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Curitiba':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Brasília':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Florianópolis':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Salvador':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Fortaleza':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Recife':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Manaus':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Ribeirão Preto':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Goiânia':\n",
    "        return 'Brazil'\n",
    "    elif country == 'João Pessoa':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Londrina':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Vitória':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Cuiabá':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Greater São Paulo Area':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Natal':\n",
    "        return 'Brazil'\n",
    "    elif country == 'São luis':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Brazil':\n",
    "        return 'Brazil'\n",
    "    elif country == 'Brasil':\n",
    "        return 'Brazil'\n",
    "    else:\n",
    "        return 'Others'\n",
    "    \n",
    "def prospect_region_international(region, country):\n",
    "    if country not in ('Brazil', 'Missing'):\n",
    "        return \"International\"\n",
    "    else:\n",
    "        return region\n",
    "try:\n",
    "    dict_prospects['prospect_location_state'] = prospect_region_international(prospectsTable['location'].split(',')[-2].replace(\" e Região\", \"\").strip(), prospect_country(prospectsTable['location'].split(',')[-1].replace(\" e Região\", \"\").strip()))\n",
    "except:\n",
    "    dict_prospects['prospect_location_state'] = 'Missing'\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist',\n",
       " 'prospect_location_state': 'São Paulo',\n",
       " 'prospect_area_migration': 'Data-to-Agile'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prospect_area_migration\n",
    "try:    \n",
    "    dict_prospects['prospect_area_migration'] = (prospectsTable['area'].split()[0]+'-to-'+dict_jobs['job_area']).strip()\n",
    "except:\n",
    "    dict_prospects['prospect_area_migration'] = ('Missing'+'-to-'+dict_jobs['job_area']).strip()\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist',\n",
       " 'prospect_location_state': 'São Paulo',\n",
       " 'prospect_area_migration': 'Data-to-Agile',\n",
       " 'prospect_smart_skills_qty': 23.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prospect_smart_skills_qty\n",
    "try:\n",
    "    dict_prospects['prospect_smart_skills_qty'] = float(len(prospectsTable['smartTags']))\n",
    "except:\n",
    "    dict_prospects['prospect_smart_skills_qty'] = 0.0\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist',\n",
       " 'prospect_location_state': 'São Paulo',\n",
       " 'prospect_area_migration': 'Data-to-Agile',\n",
       " 'prospect_smart_skills_qty': 23.0,\n",
       " 'prospect_experiences_qty': 6.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prospect_experiences_qty\n",
    "try:\n",
    "    dict_prospects['prospect_experiences_qty'] = float(len(prospectsTable['experiences']))\n",
    "except:\n",
    "    dict_prospects['prospect_experiences_qty'] = 0.0\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist',\n",
       " 'prospect_location_state': 'São Paulo',\n",
       " 'prospect_area_migration': 'Data-to-Agile',\n",
       " 'prospect_smart_skills_qty': 23.0,\n",
       " 'prospect_experiences_qty': 6.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prospect_experiences\n",
    "# total_experience_months=[]\n",
    "# total_experience_months_clean=[]\n",
    "# prospect_companies=[]\n",
    "# all_company_classifications=[]\n",
    "# for i in range(len(prospectsTable['experiences'])):\n",
    "#     try:        \n",
    "#         prospect_companies.append(prospectsTable['experiences'][i]['linkedinCompanyName'])\n",
    "        \n",
    "#         try:\n",
    "#             linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "#                 IndexName='LinkedinUsernameIndex',\n",
    "#                 KeyConditionExpression=Key('linkedinUsername').eq(prospectsTable['experiences'][i]['linkedinCompanyUsername'])\n",
    "#             )['Items']\n",
    "#             all_company_classifications.append(company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' ')))\n",
    "#         except:\n",
    "#             try:\n",
    "#                 linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "#                     IndexName='LinkedinIdIndex',\n",
    "#                     KeyConditionExpression=Key('linkedinId').eq(int(prospectsTable['experiences'][i]['linkedinCompanyId']))\n",
    "#                 )['Items']\n",
    "#                 all_company_classifications.append(company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' ')))\n",
    "#             except:\n",
    "#                 all_company_classifications.append('Missing')\n",
    "            \n",
    "#         if i == 0:\n",
    "#             if prospectsTable['experiences'][i]['to'] == None:\n",
    "#                 total_experience_months.append((int((dt.now() - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "#             else:\n",
    "#                 total_experience_months.append((int((dt.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "#             #precisa colocar o copy porque a variavel total_experience sera alterada, mas a last_experience nao pode mais ser alterada\n",
    "#             last_experience_duration_months = total_experience_months.copy()\n",
    "#             try:\n",
    "#                 last_experience_descriptions = prospectsTable['experiences'][i]['description']\n",
    "#             except:\n",
    "#                 last_experience_descriptions = ''            \n",
    "#         else:\n",
    "#             if prospectsTable['experiences'][i]['to'] == None:\n",
    "#                 total_experience_months.append((int((dt.now() - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "#                 total_experience_months_clean.append((int((dt.now() - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "#             else:\n",
    "#                 total_experience_months.append((int((dt.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "#                 total_experience_months_clean.append((int((dt.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "#     except:\n",
    "#         last_experience_duration_months=[0]\n",
    "#         total_experience_months=[0]\n",
    "#         last_experience_descriptions = ''\n",
    "#         all_company_classifications = ['Missing']\n",
    "\n",
    "# dict_prospects['prospect_companies_qty'] = len(set(prospect_companies))\n",
    "# dict_prospects['total_experience_months'] = sum(total_experience_months)\n",
    "# dict_prospects['experience_duration_months_min'] = min(total_experience_months)\n",
    "# dict_prospects['experience_duration_months_clean_avg'] = np.mean((total_experience_months_clean))\n",
    "# dict_prospects['experience_duration_months_clean_stddev'] =  np.std(total_experience_months_clean, ddof = 1)\n",
    "# dict_prospects['last_experience_duration_months_to_avg'] = float(last_experience_duration_months[0]) - float(dict_prospects['experience_duration_months_clean_avg'])\n",
    "# dict_prospects['last_experience_descriptions_word_count'] = float(len(last_experience_descriptions.split()))\n",
    "# dict_prospects['last_company_classification'] = all_company_classifications[0]\n",
    "# dict_prospects['all_company_classifications_word_count'] = float(len('; '.join(map(str, all_company_classifications)).replace(\"||\", \",\").split()))\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist',\n",
       " 'prospect_location_state': 'São Paulo',\n",
       " 'prospect_area_migration': 'Data-to-Agile',\n",
       " 'prospect_smart_skills_qty': 23.0,\n",
       " 'prospect_experiences_qty': 6.0,\n",
       " 'prospect_linkedin_about_word_count': 0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'prospect_linkedin_about_word_count'\n",
    "try:\n",
    "    dict_prospects['prospect_linkedin_about_word_count'] = float(len(prospectsTable['linkedinAboutText'].split()))\n",
    "except:\n",
    "    dict_prospects['prospect_linkedin_about_word_count'] = 0\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prospect_companies_qty': 5,\n",
       " 'total_experience_months': 80,\n",
       " 'experience_duration_months_min': 3,\n",
       " 'experience_duration_months_clean_avg': 15.4,\n",
       " 'experience_duration_months_clean_stddev': 12.973048986263793,\n",
       " 'last_experience_duration_months_to_avg': -12.4,\n",
       " 'last_experience_descriptions_word_count': 8.0,\n",
       " 'last_company_classification': 'Missing',\n",
       " 'all_company_classifications_word_count': 12.0,\n",
       " 'declared_seniority': 'Mid-level',\n",
       " 'declared_seniority_migration': 'Mid-level-to-Specialist',\n",
       " 'prospect_location_state': 'São Paulo',\n",
       " 'prospect_area_migration': 'Data-to-Agile',\n",
       " 'prospect_smart_skills_qty': 23.0,\n",
       " 'prospect_experiences_qty': 6.0,\n",
       " 'prospect_linkedin_about_word_count': 0,\n",
       " 'company_classification_migration': 'Missing-to-Empresa Tradicional B'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# company_classification_migration\n",
    "dict_prospects['company_classification_migration']=(dict_prospects['last_company_classification']+'-to-'+dict_jobs['job_company_classification']).strip()\n",
    "dict_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dict_jobs['job_seniority']\n",
    "del dict_jobs['job_company_classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1 missing columns found in the input data set: {all_company_classifications_count}\n",
      "Detected 2 unused columns in the input data set: {,all_company_classifications_word_count}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>p1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.148324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict        p1\n",
       "0        1  0.148324"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([pd.DataFrame(dict_jobs, index=[0]), pd.DataFrame(dict_prospects, index=[0])], axis=1)\n",
    "predict=h2o.mojo_predict_pandas(df, PathModelMojo).loc[:,('predict','p1')]\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>p1</th>\n",
       "      <th>suggestion</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.148324</td>\n",
       "      <td>Abordar</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predict        p1 suggestion rating\n",
       "0        1  0.148324    Abordar      7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def criar_ratings(p1):\n",
    "    if p1 <= 0.02940213015149787:\n",
    "        return 1\n",
    "    elif p1 <= 0.04974699465375872:\n",
    "        return 2\n",
    "    elif p1 <= 0.060006032316420675:\n",
    "        return 3\n",
    "    elif p1 <= 0.10576355645060076:\n",
    "        return 4\n",
    "    elif p1 <= 0.11898587992365063:\n",
    "        return 5\n",
    "    elif p1 <= 0.13668278644593498:\n",
    "        return 6\n",
    "    elif p1 <= 0.16319113762684134:\n",
    "        return 7\n",
    "    elif p1 <= 0.2150609643746747:\n",
    "        return 8\n",
    "    elif p1 <= 0.3666322315432273:\n",
    "        return 9\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "def criar_suggestion(predict):\n",
    "    if predict == 0:\n",
    "        return 'Repensar'\n",
    "    elif predict == 1:\n",
    "        return 'Abordar'\n",
    "    else:\n",
    "        return 'SUGGESTION_ERROR'\n",
    "\n",
    "predict['suggestion'] = predict.apply(lambda x: criar_suggestion(x['predict']),axis=1).astype(str)\n",
    "\n",
    "predict['rating'] = predict.apply(lambda x: criar_ratings(x['p1']),axis=1).astype(str)\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all_company_classifications_word_count': {0: 12.0},\n",
       " 'company_classification_migration': {0: 'Missing-to-Empresa Tradicional B'},\n",
       " 'declared_seniority': {0: 'Mid-level'},\n",
       " 'declared_seniority_migration': {0: 'Mid-level-to-Specialist'},\n",
       " 'experience_duration_months_clean_avg': {0: 15.4},\n",
       " 'experience_duration_months_clean_stddev': {0: 12.973048986263793},\n",
       " 'experience_duration_months_min': {0: 3},\n",
       " 'import_policy_word_count': {0: 21.0},\n",
       " 'job_area': {0: 'Agile'},\n",
       " 'job_technical_requirements_word_count': {0: 135.0},\n",
       " 'job_validation_questions_word_count': {0: 126.0},\n",
       " 'last_company_classification': {0: 'Missing'},\n",
       " 'last_experience_descriptions_word_count': {0: 8.0},\n",
       " 'last_experience_duration_months_to_avg': {0: -12.4},\n",
       " 'max_salary_offered': {0: 14000.0},\n",
       " 'prospect_area_migration': {0: 'Data-to-Agile'},\n",
       " 'prospect_companies_qty': {0: 5},\n",
       " 'prospect_experiences_qty': {0: 6.0},\n",
       " 'prospect_linkedin_about_word_count': {0: 0},\n",
       " 'prospect_location_state': {0: 'São Paulo'},\n",
       " 'prospect_smart_skills_qty': {0: 23.0},\n",
       " 'total_experience_months': {0: 80}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['all_company_classifications_word_count',\n",
    "'company_classification_migration',\n",
    "'declared_seniority',\n",
    "'declared_seniority_migration',\n",
    "'experience_duration_months_clean_avg',\n",
    "'experience_duration_months_clean_stddev',\n",
    "'experience_duration_months_min',\n",
    "'import_policy_word_count',\n",
    "'job_area',\n",
    "'job_technical_requirements_word_count',\n",
    "'job_validation_questions_word_count',\n",
    "'last_company_classification',\n",
    "'last_experience_descriptions_word_count',\n",
    "'last_experience_duration_months_to_avg',\n",
    "'max_salary_offered',\n",
    "'prospect_area_migration',\n",
    "'prospect_companies_qty',\n",
    "'prospect_experiences_qty',\n",
    "'prospect_linkedin_about_word_count',\n",
    "'prospect_location_state',\n",
    "'prospect_smart_skills_qty',\n",
    "'total_experience_months',\n",
    "]].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Lambda Handler to Deploy with API Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event, context):\n",
    "    import h2o\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import boto3\n",
    "    from boto3.dynamodb.conditions import Key\n",
    "    import datetime as dt\n",
    "    import queue\n",
    "    from threading import Thread\n",
    "    from decimal import Decimal\n",
    "    import re\n",
    "    \n",
    "    #Best Model ID:\n",
    "    BestModelId='GBM_grid_1_AutoML_1_20220602_224459_model_101.zip'\n",
    "    \n",
    "    #Keep the ratings ranges updated\n",
    "    def ratings(p1):\n",
    "        if p1 <= 0.0382443443235362:\n",
    "            return 1\n",
    "        if p1 <= 0.0530430015585711:\n",
    "            return 2\n",
    "        if p1 <= 0.0673746428820707:\n",
    "            return 3\n",
    "        if p1 <= 0.0784943959938068:\n",
    "            return 4\n",
    "        if p1 <= 0.0995685833288207:\n",
    "            return 5\n",
    "        if p1 <= 0.1190589979996429:\n",
    "            return 6\n",
    "        if p1 <= 0.1493789514138822:\n",
    "            return 7\n",
    "        elif p1 <= 0.1744927522205538:\n",
    "            return 8\n",
    "        elif p1 <= 0.2207991656421561:\n",
    "            return 9\n",
    "        else:\n",
    "            return 10\n",
    "            \n",
    "    def company_classification_const(s):\n",
    "        if s == 'Empresa pequena':\n",
    "            out='Empresa pequena'\n",
    "        elif s == 'Empresas pequenas':\n",
    "            out='Empresa pequena'\n",
    "        elif s == 'Empresa Tradicional A':\n",
    "            out='Empresa Tradicional A'\n",
    "        elif s == 'Empresa Tradicional B':\n",
    "            out='Empresa Tradicional B'\n",
    "        elif s == 'Empresa Tradicional C':\n",
    "            out='Empresa Tradicional C'\n",
    "        elif s == 'High Tech A':\n",
    "            out='High Tech A'\n",
    "        elif s == 'High Tech B':\n",
    "            out='High Tech B'\n",
    "        elif s == 'High Tech C':\n",
    "            out='High Tech C'\n",
    "        elif s == 'High Tech D':\n",
    "            out='High Tech D'\n",
    "        elif s == 'Software House A':\n",
    "            out='Software House A'\n",
    "        elif s == 'Software House B':\n",
    "            out='Software House B'\n",
    "        elif s == 'Software House C':\n",
    "            out='Software House C'\n",
    "        elif s == 'not_mapped':\n",
    "            out='Missing'\n",
    "        elif s in ('', 'null', None, 'None'):\n",
    "            out='Missing'\n",
    "        else:\n",
    "            out='UNKNOWN'\n",
    "        return out\n",
    "            \n",
    "    linkedinUsername = event['queryStringParameters']['linkedinUsername']\n",
    "    jobId = event['queryStringParameters']['jobId']\n",
    "    \n",
    "    #Eh necessario criar duas boto3 para trabalhar com multiple threads. Uma para cada thread\n",
    "    \n",
    "    #boto3_Session para a tabela jobs\n",
    "    boto_jobs = boto3.Session(region_name='us-east-1')\n",
    "    \n",
    "    #boto3_Session para a tabela prospects\n",
    "    boto_prospects = boto3.Session(region_name='us-east-1')\n",
    "    \n",
    "#     #boto3_Session para a tabela jobs\n",
    "#     boto_jobs = boto3.Session(region_name='us-east-1',\n",
    "#         aws_access_key_id='xxxxxxxxx',\n",
    "#         aws_secret_access_key='xxxxxxxx')\n",
    "\n",
    "#     #boto3_Session para a tabela prospects\n",
    "#     boto_prospects = boto3.Session(region_name='us-east-1',\n",
    "#         aws_access_key_id='xxxxxxxxx',\n",
    "#         aws_secret_access_key='xxxxxxxxx')\n",
    "    \n",
    "    #Criar funcoes de consulta ao DynamoDB para serem executadas em paralelo diminuindo o tempo\n",
    "    def dynamodb_jobs_clients_companies(jobId, boto3):        \n",
    "        jobsTable = boto3.resource('dynamodb').Table('prod-jobsTable').query(\n",
    "            IndexName='GSI1',\n",
    "            KeyConditionExpression=Key('backofficeId').eq(int(jobId))\n",
    "        )['Items']\n",
    "    \n",
    "        clientsTable = boto3.resource('dynamodb').Table('prod-clientsTable').query(\n",
    "            IndexName='idBackofficeIndex',\n",
    "            KeyConditionExpression = (Key('source').eq('backoffice') & Key('idBackoffice').eq(int(jobsTable[0]['companyId'])))\n",
    "        )['Items']\n",
    "        \n",
    "        if clientsTable[0]['linkedinURL'][-1] == '/':\n",
    "            linkedin_company_user_name = clientsTable[0]['linkedinURL'].split('/')[-2]\n",
    "        else:\n",
    "            linkedin_company_user_name = clientsTable[0]['linkedinURL'].split('/')[-1]\n",
    "    \n",
    "        linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "            IndexName='LinkedinUsernameIndex',\n",
    "            KeyConditionExpression=Key('linkedinUsername').eq(linkedin_company_user_name)\n",
    "        )['Items']\n",
    "        \n",
    "        return_object = {} \n",
    "        return_object['jobsTable'] = jobsTable\n",
    "        return_object['linkedinCompanies'] = linkedinCompanies\n",
    "        return return_object\n",
    "        \n",
    "    def dynamodb_prospects_companies(linkedinUsername, boto3):        \n",
    "        prospectsTable = boto3.resource('dynamodb').Table('prod-prospectsTable').get_item(Key={'linkedinUsername': linkedinUsername})['Item']\n",
    "    \n",
    "        dict_prospects={}\n",
    "        total_experience_months=[]\n",
    "        total_experience_months_clean=[]\n",
    "        prospect_companies=[]        \n",
    "        all_company_classifications=[]\n",
    "    def dynamodb_prospects_companies(linkedinUsername, boto3):        \n",
    "        prospectsTable = boto3.resource('dynamodb').Table('prod-prospectsTable').get_item(Key={'linkedinUsername': linkedinUsername})['Item']\n",
    "    \n",
    "        dict_prospects={}\n",
    "        total_experience_months=[]\n",
    "        total_experience_months_clean=[]\n",
    "        prospect_companies=[]        \n",
    "        all_company_classifications=[]\n",
    "        try:\n",
    "            for i in range(len(prospectsTable['experiences'])):\n",
    "                prospect_companies.append(prospectsTable['experiences'][i]['linkedinCompanyName'])\n",
    "    \n",
    "                try:\n",
    "                    linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "                        IndexName='LinkedinUsernameIndex',\n",
    "                        KeyConditionExpression=Key('linkedinUsername').eq(prospectsTable['experiences'][i]['linkedinCompanyUsername'])\n",
    "                    )['Items']\n",
    "                    all_company_classifications.append(company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' ')))\n",
    "                except Exception as e:                    \n",
    "                    print(\"e.1: \"+ str(e))\n",
    "                    try:\n",
    "                        linkedinCompanies = boto3.resource('dynamodb').Table('prod-linkedinCompanies').query(\n",
    "                            IndexName='LinkedinIdIndex',\n",
    "                            KeyConditionExpression=Key('linkedinId').eq(int(prospectsTable['experiences'][i]['linkedinCompanyId']))\n",
    "                        )['Items']\n",
    "                        all_company_classifications.append(company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' ')))\n",
    "                    except Exception as e:\n",
    "                        print(\"e.2: \"+ str(e))\n",
    "                        all_company_classifications.append('Missing')\n",
    "    \n",
    "                if i == 0:\n",
    "                    if prospectsTable['experiences'][i]['to'] == None:\n",
    "                        total_experience_months.append((int((dt.datetime.now() - dt.datetime.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                    else:\n",
    "                        total_experience_months.append((int((dt.datetime.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.datetime.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                    #precisa colocar o copy porque a variavel total_experience sera alterada, mas a last_experience nao pode mais ser alterada\n",
    "                    last_experience_duration_months = total_experience_months.copy()\n",
    "                    try:\n",
    "                        last_experience_descriptions = prospectsTable['experiences'][i]['description']\n",
    "                    except Exception as e:\n",
    "                        print(\"e.3: \"+ str(e))\n",
    "                        last_experience_descriptions = ''\n",
    "                else:\n",
    "                    try:\n",
    "                        if prospectsTable['experiences'][i]['to'] == None:\n",
    "                            total_experience_months.append((int((dt.datetime.now() - dt.datetime.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                            total_experience_months_clean.append((int((dt.datetime.now() - dt.datetime.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                        else:\n",
    "                            total_experience_months.append((int((dt.datetime.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.datetime.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                            total_experience_months_clean.append((int((dt.datetime.strptime(prospectsTable['experiences'][i]['to'][:10], \"%Y-%m-%d\") - dt.datetime.strptime(prospectsTable['experiences'][i]['from'][:10], \"%Y-%m-%d\")).days/30)))\n",
    "                    except Exception as e:\n",
    "                        print(\"e.3b: \"+ str(e))\n",
    "        except Exception as e:\n",
    "            print(\"e.4: \"+ str(e))\n",
    "            last_experience_duration_months=[0]\n",
    "            total_experience_months_clean=[0,0.1]\n",
    "            total_experience_months=[0]\n",
    "            last_experience_descriptions = ''\n",
    "            all_company_classifications = ['Missing']\n",
    "    \n",
    "        dict_prospects['prospect_companies_qty'] = len(set(prospect_companies))\n",
    "        dict_prospects['total_experience_months'] = sum(total_experience_months)\n",
    "        dict_prospects['experience_duration_months_min'] = min(total_experience_months)\n",
    "        dict_prospects['experience_duration_months_clean_avg'] = np.nan_to_num(np.mean((total_experience_months_clean)))\n",
    "        dict_prospects['experience_duration_months_clean_stddev'] =  np.nan_to_num(np.std(total_experience_months_clean, ddof = 1))\n",
    "        dict_prospects['last_experience_duration_months_to_avg'] = float(last_experience_duration_months[0]) - float(dict_prospects['experience_duration_months_clean_avg'])\n",
    "        dict_prospects['last_experience_descriptions_word_count'] = float(len(last_experience_descriptions.split()))\n",
    "        dict_prospects['last_company_classification'] = all_company_classifications[0]\n",
    "#         dict_prospects['all_company_classifications_word_count'] = float(len('; '.join(map(str, all_company_classifications)).replace(\"||\", \",\").split()))\n",
    "        dict_prospects['all_company_classifications_count'] = (sum(map((lambda x: (0 if x.strip() == 'Missing' else 1)), all_company_classifications)))\n",
    "        \n",
    "        return_object = {} \n",
    "        return_object['prospectsTable'] = prospectsTable\n",
    "        return_object['dict_prospects'] = dict_prospects\n",
    "        return return_object\n",
    "\n",
    "    #Executar as duas funcoes de forma assincrona\n",
    "    try:\n",
    "        #criar q1 e q2 para receber o return de cada funcao\n",
    "        q1 = queue.Queue()\n",
    "        q2 = queue.Queue()\n",
    "        #criar as duas tarefas\n",
    "        t1 = Thread(target = lambda q, arg1, arg2 : q.put(dynamodb_jobs_clients_companies(arg1, arg2)), args = (q1, jobId, boto_jobs))\n",
    "        t2 = Thread(target = lambda q, arg1, arg2 : q.put(dynamodb_prospects_companies(arg1, arg2)), args = (q2, linkedinUsername, boto_prospects))\n",
    "        #iniciar as duas tarefas simutaneamente.\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        #unir as duas tarefas para garantir que a proxima tarefa seja iniciada somente quando as duas terminarem\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "        \n",
    "        #recebar o return da funcao\n",
    "        while not q1.empty():\n",
    "            return_object_jobs_clients_companies = q1.get()\n",
    "        while not q2.empty():\n",
    "            return_object_prospects_companies = q2.get()\n",
    "    except Exception as e:\n",
    "        print(\"e.5: \"+ str(e))\n",
    "        #criar q1 e q2 para receber o return de cada funcao\n",
    "        q1 = queue.Queue()\n",
    "        q2 = queue.Queue()\n",
    "        #criar as duas tarefas\n",
    "        t1 = Thread(target = lambda q, arg1, arg2 : q.put(dynamodb_jobs_clients_companies(arg1, arg2)), args = (q1, jobId, boto3))\n",
    "        t2 = Thread(target = lambda q, arg1, arg2 : q.put(dynamodb_prospects_companies(arg1, arg2)), args = (q2, linkedinUsername, boto3))\n",
    "        #iniciar as duas tarefas simutaneamente.\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        #unir as duas tarefas para garantir que a proxima tarefa seja iniciada somente quando as duas terminarem\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "        \n",
    "        #recebar o return da funcao\n",
    "        while not q1.empty():\n",
    "            return_object_jobs_clients_companies = q1.get()\n",
    "        while not q2.empty():\n",
    "            return_object_prospects_companies = q2.get()\n",
    "            \n",
    "    jobsTable = return_object_jobs_clients_companies['jobsTable']\n",
    "    linkedinCompanies = return_object_jobs_clients_companies['linkedinCompanies']\n",
    "    prospectsTable = return_object_prospects_companies['prospectsTable']\n",
    "    dict_prospects = return_object_prospects_companies['dict_prospects']\n",
    "\n",
    "    #Start empty dictionary\n",
    "    dict_jobs={}\n",
    "\n",
    "    ## job_seniority = 'profile.seniority'\n",
    "    def job_seniority_const(s):\n",
    "        if s in (\"Júnior\", \"junior\", \"Junior\"):\n",
    "            out=\"Junior\"\n",
    "        elif s in (\"Pleno\", \"pleno\"):\n",
    "            out=\"Mid-level\"\n",
    "        elif s in (\"Senior\", \"Sênior\", \"senior\"):\n",
    "            out=\"Senior\"\n",
    "        elif s in (\"Especialista\", \"especialista\"):\n",
    "            out=\"Specialist\"\n",
    "        elif s == \"Tech Lead\":\n",
    "            out=\"Tech Lead\"\n",
    "        elif s == \"Tech Manager\":\n",
    "            out=\"Tech Manager\"\n",
    "        elif s in ('', 'null', None, 'None'):\n",
    "            out=\"Missing\"\n",
    "        else:\n",
    "            out=\"UNKNOWN\"\n",
    "        return out\n",
    "    \n",
    "    dict_jobs['job_seniority'] = job_seniority_const(jobsTable[0]['profile']['seniority'])\n",
    "\n",
    "    ## job_area = 'area'\n",
    "    try:\n",
    "        dict_jobs['job_area'] = jobsTable[0]['area']\n",
    "    except Exception as e:\n",
    "        print(\"e.6: \"+ str(e))\n",
    "        dict_jobs['job_area'] = 'Missing'\n",
    "\n",
    "    ## max_salary_offered = 'maxsalary'\n",
    "    try:\n",
    "        dict_jobs['max_salary_offered'] = float(jobsTable[0]['maxSalary'])\n",
    "    except Exception as e:\n",
    "        print(\"e.7: \"+ str(e))\n",
    "        dict_jobs['max_salary_offered'] = 0\n",
    "        \n",
    "    ## import_policy_word_count = 'importPolicy'\n",
    "    try:\n",
    "        dict_jobs['import_policy_word_count'] = float(len(jobsTable[0]['importPolicy'].split()))\n",
    "    except Exception as e:\n",
    "        print(\"e.8: \"+ str(e))\n",
    "        dict_jobs['import_policy_word_count'] = 0\n",
    "\n",
    "    ## job_technical_requirements_word_count = 'alignments.intendedTechnicalInfo'\n",
    "    try:\n",
    "        dict_jobs['job_technical_requirements_word_count'] = float(len(jobsTable[0]['alignments']['intendedTechnicalInfo'].split()))\n",
    "    except Exception as e:\n",
    "        print(\"e.9: \"+ str(e))\n",
    "        dict_jobs['job_technical_requirements_word_count'] = 0\n",
    "\n",
    "    ## job_validation_questions_word_count = 'validationQuestions'\n",
    "    try:\n",
    "        dict_jobs['job_validation_questions_word_count'] = float(len(jobsTable[0]['validationQuestions'].split()))\n",
    "    except Exception as e:\n",
    "        print(\"e.10: \"+ str(e))\n",
    "        dict_jobs['job_validation_questions_word_count'] = 0\n",
    "        \n",
    "    ## company_classification\n",
    "    try:\n",
    "        dict_jobs['job_company_classification'] = company_classification_const(linkedinCompanies[0]['category'].replace(' - ', ' '))\n",
    "    except Exception as e:\n",
    "        print(\"e.11: \"+ str(e))\n",
    "        dict_jobs['job_company_classification'] = 'Missing'\n",
    "\n",
    "    \n",
    "    ## prospectsTable\n",
    "\n",
    "    ## declared_seniority = 'declaredseniority'\n",
    "    try:\n",
    "        dict_prospects['declared_seniority'] = job_seniority_const(prospectsTable['declaredSeniority'])\n",
    "    except Exception as e:\n",
    "        print(\"e.12: \"+ str(e))\n",
    "        dict_prospects['declared_seniority'] = 'Missing'\n",
    "\n",
    "    # 'declared_seniority_migration'\n",
    "    dict_prospects['declared_seniority_migration'] = (dict_prospects['declared_seniority']+'-to-'+dict_jobs['job_seniority']).strip()\n",
    "\n",
    "    #Criacao das variaveis de pais com base na variavel propesct_location do linkedin. Para comparar abordagens de talentos que moram fora do Brasil\n",
    "    def prospect_country(country):\n",
    "        if pd.isna(country):\n",
    "            return \"Missing\"\n",
    "        elif country == 'São Paulo':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Rio de Janeiro':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Campinas':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Belo Horizonte':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Porto Alegre':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Curitiba':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Brasília':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Florianópolis':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Salvador':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Fortaleza':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Recife':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Manaus':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Ribeirão Preto':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Goiânia':\n",
    "            return 'Brazil'\n",
    "        elif country == 'João Pessoa':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Londrina':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Vitória':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Cuiabá':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Greater São Paulo Area':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Natal':\n",
    "            return 'Brazil'\n",
    "        elif country == 'São luis':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Brazil':\n",
    "            return 'Brazil'\n",
    "        elif country == 'Brasil':\n",
    "            return 'Brazil'\n",
    "        else:\n",
    "            return 'Others'\n",
    "        \n",
    "    def prospect_region_international(region, country):\n",
    "        if country not in ('Brazil', 'Missing'):\n",
    "            return \"International\"\n",
    "        else:\n",
    "            return region\n",
    "    try:\n",
    "        dict_prospects['prospect_location_state'] = prospect_region_international(prospectsTable['location'].split(',')[-2].replace(\" e Região\", \"\").strip(), prospect_country(prospectsTable['location'].split(',')[-1].replace(\" e Região\", \"\").strip()))\n",
    "    except Exception as e:\n",
    "        print(\"e.13: \"+ str(e))\n",
    "        dict_prospects['prospect_location_state'] = 'Missing'\n",
    "        \n",
    "    ## prospect_area_migration\n",
    "    try:    \n",
    "        dict_prospects['prospect_area_migration'] = (prospectsTable['area'].split()[0]+'-to-'+dict_jobs['job_area']).strip()\n",
    "    except Exception as e:\n",
    "        print(\"e.14: \"+ str(e))\n",
    "        dict_prospects['prospect_area_migration'] = ('Missing'+'-to-'+dict_jobs['job_area']).strip()\n",
    "\n",
    "    ## prospect_smart_skills_qty\n",
    "    try:\n",
    "        dict_prospects['prospect_smart_skills_qty'] = float(len(prospectsTable['smartTags']))\n",
    "    except Exception as e:\n",
    "        print(\"e.15: \"+ str(e))\n",
    "        dict_prospects['prospect_smart_skills_qty'] = 0.0\n",
    "\n",
    "    ## prospect_experiences_qty\n",
    "    try:\n",
    "        dict_prospects['prospect_experiences_qty'] = float(len(prospectsTable['experiences']))\n",
    "    except Exception as e:\n",
    "        print(\"e.16: \"+ str(e))\n",
    "        dict_prospects['prospect_experiences_qty'] = 0.0\n",
    "    \n",
    "    # 'prospect_linkedin_about_word_count'\n",
    "    try:\n",
    "        dict_prospects['prospect_linkedin_about_word_count'] = float(len(prospectsTable['linkedinAboutText'].split()))\n",
    "    except Exception as e:\n",
    "        print(\"e.17: \"+ str(e))\n",
    "        dict_prospects['prospect_linkedin_about_word_count'] = 0\n",
    "        \n",
    "    # company_classification_migration\n",
    "    dict_prospects['company_classification_migration']=(dict_prospects['last_company_classification']+'-to-'+dict_jobs['job_company_classification']).strip()\n",
    "    \n",
    "    del dict_jobs['job_seniority']\n",
    "    del dict_jobs['job_company_classification']\n",
    "    \n",
    "    df = pd.concat([pd.DataFrame(dict_jobs, index=[0]), pd.DataFrame(dict_prospects, index=[0])], axis=1)\n",
    "    \n",
    "    predict=h2o.mojo_predict_pandas(df.set_index('last_company_classification', inplace=False), mojo_zip_path=BestModelId, genmodel_jar_path='h2o-genmodel.jar', verbose=False).loc[:,('predict','p1')]\n",
    "            \n",
    "    def suggestion(predict):\n",
    "        if predict == 0:\n",
    "            return 'Repensar'\n",
    "        elif predict == 1:\n",
    "            return 'Abordar'\n",
    "        else:\n",
    "            return 'SUGGESTION_ERROR'\n",
    "    \n",
    "    predict['suggestion'] = predict.apply(lambda x: suggestion(x['predict']),axis=1).astype(str)\n",
    "    \n",
    "    predict['rating'] = predict.apply(lambda x: ratings(x['p1']),axis=1).astype(str)\n",
    "\n",
    "    body = {\n",
    "        \"message\": \"Prediction executed successfully!\"        \n",
    "    }\n",
    "\n",
    "    body['probability'] = round(predict['p1'][0],4)\n",
    "    body['rating'] = predict['rating'][0]\n",
    "    body['suggestion'] = predict['suggestion'][0]\n",
    "    \n",
    "    response = {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(body),\n",
    "        \"headers\": {\n",
    "            \"Access-Control-Allow-Origin\": \"*\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# # DEV\n",
    "# event={\n",
    "#     \"queryStringParameters\":{\"jobId\":\"2329\",\n",
    "#                              \"linkedinUsername\":\"patriciakano\"}\n",
    "# }\n",
    "# context='context'\n",
    "# print(lambda_handler(event, context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Lambda + API Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={\n",
    "  \"jobId\": 1198,\n",
    "  \"linkedinUsername\": \"maxuel-reis-1b343621\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200510489698.png'}\n",
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200513972178.png'}\n",
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200516973655.png'}\n",
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200520137308.png'}\n",
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200523370732.png'}\n",
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200526507038.png'}\n",
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200529648519.png'}\n",
      "{'message': 'Prediction executed successfully!', 'probability': 0.102, 'rating': '6', 'suggestion': 'Repensar', 'image_path': '1198_maxuel-reis-1b343621_20220702200532867650.png'}\n",
      "3.19 s ± 41.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import requests\n",
    "\n",
    "# Parâmetros do modelo\n",
    "endpoint_modelo = 'https://lp1027iq13.execute-api.us-east-1.amazonaws.com/dev/get-predict'\n",
    "# https://e87iurnmfh.execute-api.us-east-1.amazonaws.com/dev/get-predict\n",
    "\n",
    "# Definição dos inputs\n",
    "params = dict\n",
    "\n",
    "resultado = requests.get(endpoint_modelo, params = params)\n",
    "print(resultado.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_end_point = datascored_df.query('job_id == 2259')[['linkedin_user_name', 'approach_created_at_date', 'job_id', 'predict', 'p0', 'p1']].reset_index()\n",
    "\n",
    "# for i in range(len(df_end_point)):\n",
    "#     temp = df_end_point.loc[i:i, ('linkedin_user_name','job_id', 'p1')].to_dict()\n",
    "\n",
    "#     dict={\n",
    "#       \"jobId\": temp['job_id'][i],\n",
    "#       \"linkedinUsername\": temp['linkedin_user_name'][i]\n",
    "#     }  \n",
    "\n",
    "#     # Parâmetros do modelo\n",
    "#     endpoint_modelo = 'https://io9fmel6yc.execute-api.us-east-1.amazonaws.com/dev/get-predict'\n",
    "#     # https://e87iurnmfh.execute-api.us-east-1.amazonaws.com/dev/get-predict\n",
    "\n",
    "#     # Definição dos inputs\n",
    "#     params = dict\n",
    "\n",
    "#     resultado = requests.get(endpoint_modelo, params = params)\n",
    "#     temp2 = resultado.json()\n",
    "#     print(round(temp['p1'][i],4))\n",
    "#     print(temp2['probability'])\n",
    "    \n",
    "#     print(round(temp['p1'][i],4) == temp2['probability'])"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (arn:aws:sagemaker:us-east-1:245799943033:image-version/datascienceintera/5)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:245799943033:image-version/datascienceintera/5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
